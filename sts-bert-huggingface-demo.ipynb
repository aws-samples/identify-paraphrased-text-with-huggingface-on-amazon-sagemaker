{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f60b1f6",
   "metadata": {},
   "source": [
    "# Paraphrase Identification using HuggingFace on SageMaker - Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17341640",
   "metadata": {},
   "source": [
    "Many customers today deal with use cases where identifying paraphrased text has business value. For example, by identifying sentence paraphrases, a text summarization system could remove redundant information. Another application is to identify plagiarized documents. Here, we will fine-tune a Hugging Face transformer on SageMaker to identify paraphrased sentence pairs in a few, simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f11bda",
   "metadata": {},
   "source": [
    "# Setup and install libraries\n",
    "\n",
    "We will begin by installing the necessary libraries, importing them into the development environment, selecting the appropriate IAM role and the Amazon S3 bucket.\n",
    "\n",
    "Select the `conda_pytorch_p36` notebook kernel\n",
    "\n",
    "Install the required libraries from Hugging Face - `transformers` and `datasets`. We'll also ensure that we have the updated version of `SageMaker Python SDK`\n",
    "\n",
    "Documentation on [Installing Transformers](https://huggingface.co/docs/transformers/installation) and [Installing SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805fa8a",
   "metadata": {},
   "source": [
    "Note: if you see the following message after executing the pip install cell below, you can safely ignore it, it does not affect the packages and code in this notebook: \"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\n",
    "spacy 3.0.6 requires pydantic<1.8.0,>=1.7.1, but you have pydantic 1.8.2 which is incompatible.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606d7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install \"sagemaker\" \"transformers==4.6.1\" \"datasets==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc7ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface\n",
    "import sagemaker\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc99f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role Arn: arn:aws:iam::410679667861:role/SageMakerRole\n",
      "SageMaker - Amazon S3 Bucket: sts-sbert-paws-blog\n",
      "SageMaker Session Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "session_bucket = 'sts-sbert-paws-blog'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=session_bucket)\n",
    "\n",
    "print(f\"SageMaker Role Arn: {role}\")\n",
    "print(f\"SageMaker - Amazon S3 Bucket: {sess.default_bucket()}\")\n",
    "print(f\"SageMaker Session Region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74fc2b",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9abe1",
   "metadata": {},
   "source": [
    "We will be using the `PAWS (Paraphrase Adversaries from Word Scrambling)` dataset. The final labled dataset contains pairs that are genreated from both word swapping and back translation methods. All pairs have human judgements on both paraphrasing and fluency and they are also split into `Train/Validation/Test` sections. The `Train` dataset contains a total of 49,401 sentence pairs, while the `Validation` and `Test` datasets contain a total of 8,000 sentence pairs each.\n",
    "\n",
    "![image info](./img/PAWS-dataset-sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ead4610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d970e6b7f39945089d1edde0f1b2081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2500.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31dcf03e16b43f38ada2e010c413f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1554.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset paws/labeled_final (download: 4.47 MiB, generated: 15.45 MiB, post-processed: Unknown size, total: 19.92 MiB) to /home/ec2-user/.cache/huggingface/datasets/paws/labeled_final/1.1.0/09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791104294ec94704bcd548f8b17f94c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4687157.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5be468bb5fc463aa095238bc6a7c56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab32b1ce4004b29b16f2c708c4dee82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e164b2c70d046f2a579e95b507a979f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset paws downloaded and prepared to /home/ec2-user/.cache/huggingface/datasets/paws/labeled_final/1.1.0/09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val, dataset_test = load_dataset(\"paws\", \"labeled_final\", split=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30839f4b",
   "metadata": {},
   "source": [
    "# Understand Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc296c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = dataset_train.to_pandas()\n",
    "\n",
    "ax = sns.countplot(x=\"label\", data=df)\n",
    "ax.set_title('Label Count for PAWS Dataset', fontsize=15)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), ha='center', va='top', color='white', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cad5fc",
   "metadata": {},
   "source": [
    "We can see the dataset is slightly imbalanced, a few class imbalance strategies can be applied such as _oversampling_, _undersampling_, _SMOTE_, etc. For the purpose of demonstration, we will not implement these strategies and assume that we have a fairly balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c60df63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.558126\n",
       "1    0.441874\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb1b98",
   "metadata": {},
   "source": [
    "# Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c68f7b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cae7c099114f2aa7298d4f3bb4ad3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4364263a634e18bbcb9c716d19733a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a49773ec4a44d7e9199646f907c1f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer_and_model_name = 'roberta-large'\n",
    "\n",
    "# Download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_and_model_name)\n",
    "\n",
    "# Tokenizer helper function\n",
    "def tokenize(batch, max_len=128):\n",
    "    return tokenizer(batch['sentence1'], batch['sentence2'], max_length=max_len, truncation=True)\n",
    "\n",
    "dataset_train_tokenized = dataset_train.map(tokenize, batched=True, batch_size=len(dataset_train))\n",
    "dataset_val_tokenized = dataset_val.map(tokenize, batched=True, batch_size=len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1b68495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['attention_mask', 'id', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "     num_rows: 49401\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['attention_mask', 'id', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "     num_rows: 8000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['attention_mask', 'id', 'input_ids', 'label', 'sentence1', 'sentence2'],\n",
       "     num_rows: 8000\n",
       " }))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_tokenized, dataset_val_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cf33e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokenized datasets to PyTorch tensors\n",
    "dataset_train_tokenized = dataset_train_tokenized.rename_column(\"label\", \"labels\")\n",
    "dataset_train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "dataset_val_tokenized = dataset_val_tokenized.rename_column(\"label\", \"labels\")\n",
    "dataset_val_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9ee84",
   "metadata": {},
   "source": [
    "# Upload tokenized dataset to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a4312",
   "metadata": {},
   "source": [
    "After we processed the datasets we are going to use the new `FileSystem` [integration](https://huggingface.co/docs/datasets/filesystems.html) to upload our dataset to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2d2b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "s3_prefix = 'sts-paws-datasets/paws-tokenized/' + tokenizer_and_model_name\n",
    "\n",
    "# save train dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "dataset_train_tokenized.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save val dataset to s3\n",
    "val_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/val'\n",
    "dataset_val_tokenized.save_to_disk(val_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3670000",
   "metadata": {},
   "source": [
    "# Model Training: Amazon SageMaker - Hugging Face\n",
    "\n",
    "BERT stands for Bidirectional Encoder Representations from Transformers, a transformer based model that uses Attention mechanism for learning contextual relationships among words of a sentence. With Hugging Face library, we can take a pre-trained BERT model that has learned contextual relationships from Wikipedia, books, other corpus, and fine tune the model on a specific set of paraphrase sentence pairs.\n",
    "\n",
    "![](img/bert_transfer_learning.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c21a4f",
   "metadata": {},
   "source": [
    "This illustration is from Jacob D. et al (2019). The overall pre-training and fine-tuning procedure for BERT. Retrieved from https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7607cb4e",
   "metadata": {},
   "source": [
    "Other resources for learning more about transfer learning and BERT include - 1) [Recent Advances in Language Model Fine-tuning](https://ruder.io/recent-advances-lm-fine-tuning/) by Sebastian Ruder; 2) [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar; 3) [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805); 4) [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) and 5) [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068e692",
   "metadata": {},
   "source": [
    "# Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9ad02",
   "metadata": {},
   "source": [
    "Now that we are done with data preparation, we are ready to fine-tune our pre-trained roberta-large model on the task of identifying paraphrased sentences. We can leverage the HuggingFace Estimator class within SageMaker to initiate the fine-tuning process in a few simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385a673",
   "metadata": {},
   "source": [
    "\n",
    "Note: when fine-tuning HuggingFace transformers, ensure that the `transformers_version`, `pytorch_version` and `py_version` are aligned, as described [here](https://huggingface.co/docs/sagemaker/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d47a3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 4,\n",
    "                   'train_batch_size': 16,\n",
    "                   'model_name': tokenizer_and_model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1aa0616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sts-sbert-paws-blog'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Optional: View session bucket name\n",
    "# f's3://{sess.default_bucket()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e80d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11f4c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "                            entry_point='train.py',\n",
    "                            source_dir='./scripts',\n",
    "                            output_path=f's3://{sess.default_bucket()}',\n",
    "                            base_job_name='huggingface-sdk-extension',\n",
    "                            instance_type='ml.p3.8xlarge',\n",
    "                            instance_count=1,\n",
    "                            volume_size=100,\n",
    "                            transformers_version='4.6.1',\n",
    "                            pytorch_version='1.7.1',\n",
    "                            py_version='py36',\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            metric_definitions=metric_definitions\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5eb36",
   "metadata": {},
   "source": [
    "We will be calling our `train.py` file store in `./scripts/train.py`, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5050f8cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, set_seed\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score, precision_recall_fscore_support\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_from_disk\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[37m# Set seed for reproducibility\u001b[39;49;00m\n",
      "\u001b[37m# https://huggingface.co/transformers/internal/trainer_utils.html?highlight=seed#transformers.set_seed\u001b[39;49;00m\n",
      "set_seed(\u001b[34m42\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eval_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m500\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34m5e-5\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--gradient_accumulation_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m16\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--output_data_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--test_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    args, _ = parser.parse_known_args()\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(args)\n",
      "    \n",
      "    \u001b[37m# Set up logging\u001b[39;49;00m\n",
      "    logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "\n",
      "    logging.basicConfig(\n",
      "        level=logging.getLevelName(\u001b[33m\"\u001b[39;49;00m\u001b[33mINFO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\n",
      "        handlers=[logging.StreamHandler(sys.stdout)],\n",
      "        \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# load datasets\u001b[39;49;00m\n",
      "    train_dataset = load_from_disk(args.training_dir)\n",
      "    test_dataset = load_from_disk(args.test_dir)\n",
      "\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded train_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(train_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded test_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(test_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# compute metrics function for binary classification\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcompute_metrics\u001b[39;49;00m(pred):\n",
      "        labels = pred.label_ids\n",
      "        preds = pred.predictions.argmax(-\u001b[34m1\u001b[39;49;00m)\n",
      "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mbinary\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        acc = accuracy_score(labels, preds)\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: acc, \u001b[33m\"\u001b[39;49;00m\u001b[33mf1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: f1, \u001b[33m\"\u001b[39;49;00m\u001b[33mprecision\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: precision, \u001b[33m\"\u001b[39;49;00m\u001b[33mrecall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: recall}\n",
      "\n",
      "    \u001b[37m# download model from model hub\u001b[39;49;00m\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(args.model_name, num_labels=\u001b[34m2\u001b[39;49;00m)\n",
      "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
      "\n",
      "    \u001b[37m# define training args\u001b[39;49;00m\n",
      "    training_args = TrainingArguments(\n",
      "        output_dir=args.model_dir,\n",
      "        num_train_epochs=args.epochs,\n",
      "        per_device_train_batch_size=args.train_batch_size,\n",
      "        per_device_eval_batch_size=args.eval_batch_size,\n",
      "        warmup_steps=args.warmup_steps,\n",
      "        evaluation_strategy=\u001b[33m\"\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
      "        logging_dir=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.output_data_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/logs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        learning_rate=\u001b[36mfloat\u001b[39;49;00m(args.learning_rate),\n",
      "        load_best_model_at_end=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        save_total_limit=\u001b[34m1\u001b[39;49;00m,\n",
      "    )\n",
      "        \n",
      "    \u001b[37m# create Trainer instance\u001b[39;49;00m\n",
      "    trainer = Trainer(\n",
      "        model=model,\n",
      "        args=training_args,\n",
      "        compute_metrics=compute_metrics,\n",
      "        train_dataset=train_dataset,\n",
      "        eval_dataset=test_dataset,\n",
      "        tokenizer=tokenizer,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# train model\u001b[39;49;00m\n",
      "    trainer.train()\n",
      "\n",
      "    \u001b[37m# evaluate model\u001b[39;49;00m\n",
      "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\n",
      "\n",
      "    \u001b[37m# writes eval result to file which can be accessed later in s3 ouput\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(args.output_data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33meval_results.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m writer:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m***** Eval results *****\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[34mfor\u001b[39;49;00m key, value \u001b[35min\u001b[39;49;00m \u001b[36msorted\u001b[39;49;00m(eval_result.items()):\n",
      "            writer.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m = \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvalue\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Saves the model to s3\u001b[39;49;00m\n",
      "    trainer.save_model(args.model_dir)\n"
     ]
    }
   ],
   "source": [
    "## Optional: View training script\n",
    "# !pygmentize ./scripts/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bf3cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-24 21:44:52 Starting - Starting the training job...\n",
      "2022-01-24 21:44:54 Starting - Launching requested ML instancesProfilerReport-1643060692: InProgress\n",
      ".........\n",
      "2022-01-24 21:46:47 Starting - Preparing the instances for training.........\n",
      "2022-01-24 21:48:04 Downloading - Downloading input data...\n",
      "2022-01-24 21:48:46 Training - Downloading the training image...............\n",
      "2022-01-24 21:51:25 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:16,086 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:16,129 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:17,545 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:18,085 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 16,\n",
      "        \"model_name\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
      "        \"epochs\": 4\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sm-sts-blog-1643060692\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sts-sbert-paws-blog/sm-sts-blog-1643060692/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":4,\"model_name\":\"sentence-transformers/paraphrase-mpnet-base-v2\",\"train_batch_size\":16}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sts-sbert-paws-blog/sm-sts-blog-1643060692/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":4,\"model_name\":\"sentence-transformers/paraphrase-mpnet-base-v2\",\"train_batch_size\":16},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sm-sts-blog-1643060692\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sts-sbert-paws-blog/sm-sts-blog-1643060692/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"4\",\"--model_name\",\"sentence-transformers/paraphrase-mpnet-base-v2\",\"--train_batch_size\",\"16\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=sentence-transformers/paraphrase-mpnet-base-v2\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --epochs 4 --model_name sentence-transformers/paraphrase-mpnet-base-v2 --train_batch_size 16\u001b[0m\n",
      "\u001b[34mNamespace(epochs=4, eval_batch_size=64, gradient_accumulation_steps=16, learning_rate=5e-05, model_dir='/opt/ml/model', model_name='sentence-transformers/paraphrase-mpnet-base-v2', n_gpus='4', output_data_dir='/opt/ml/output/data', test_dir='/opt/ml/input/data/test', train_batch_size=16, training_dir='/opt/ml/input/data/train', warmup_steps=500)\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:22,805 - __main__ - INFO -  loaded train_dataset length is: 49401\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:22,805 - __main__ - INFO -  loaded test_dataset length is: 8000\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:22,840 - filelock - INFO - Lock 140551903188472 acquired on /root/.cache/huggingface/transformers/96eb1c084a276166de559d1ad85205eb6ba5dd929bb90f41af67e0d9d7a0c6fd.bbbef2c70c87c42bb5499099ec8bd707180a1fa6a72cbd40f6f23649d8bd6d8c.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:22,867 - filelock - INFO - Lock 140551903188472 released on /root/.cache/huggingface/transformers/96eb1c084a276166de559d1ad85205eb6ba5dd929bb90f41af67e0d9d7a0c6fd.bbbef2c70c87c42bb5499099ec8bd707180a1fa6a72cbd40f6f23649d8bd6d8c.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:22,894 - filelock - INFO - Lock 140550882998592 acquired on /root/.cache/huggingface/transformers/992e9e88844a23031919226d183d2dec1973bb93482dd767713146d989b9972e.aabd9267f2a2af6ec34667d063ffbcacdfd7da949d6c2f6e145f113dacce0263.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:31,265 - filelock - INFO - Lock 140550882998592 released on /root/.cache/huggingface/transformers/992e9e88844a23031919226d183d2dec1973bb93482dd767713146d989b9972e.aabd9267f2a2af6ec34667d063ffbcacdfd7da949d6c2f6e145f113dacce0263.lock\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at sentence-transformers/paraphrase-mpnet-base-v2 were not used when initializing MPNetForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,781 - filelock - INFO - Lock 140550875831264 acquired on /root/.cache/huggingface/transformers/d48c7a894f2f0438eb62fcb8884f11ff35ea7e1e44ca0274b6ae0a288fca285b.98b26f9c960899aa0e99c10a12750104e467743b3b460b79fa7d76907549319b.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,813 - filelock - INFO - Lock 140550875831264 released on /root/.cache/huggingface/transformers/d48c7a894f2f0438eb62fcb8884f11ff35ea7e1e44ca0274b6ae0a288fca285b.98b26f9c960899aa0e99c10a12750104e467743b3b460b79fa7d76907549319b.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,838 - filelock - INFO - Lock 140550875802984 acquired on /root/.cache/huggingface/transformers/ae71b00a0e284b08264509b65ada716ffa2872f3063c4c939b59959e62d4ab75.4e84197f9f04666b541217ec3e1bd301b154ec9bfa8b968b3f9185b34bd73da6.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,877 - filelock - INFO - Lock 140550875802984 released on /root/.cache/huggingface/transformers/ae71b00a0e284b08264509b65ada716ffa2872f3063c4c939b59959e62d4ab75.4e84197f9f04666b541217ec3e1bd301b154ec9bfa8b968b3f9185b34bd73da6.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,928 - filelock - INFO - Lock 140550875801976 acquired on /root/.cache/huggingface/transformers/e341629aba7afac8fd72ecdea6343b69a33eb5bb76ced6b288dbe1e666c35c47.18ebceb237d999d8f1cb15935e35b314f3e73dd6c4f65e119f4790fa226c9236.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,953 - filelock - INFO - Lock 140550875801976 released on /root/.cache/huggingface/transformers/e341629aba7afac8fd72ecdea6343b69a33eb5bb76ced6b288dbe1e666c35c47.18ebceb237d999d8f1cb15935e35b314f3e73dd6c4f65e119f4790fa226c9236.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:32,978 - filelock - INFO - Lock 140550875830480 acquired on /root/.cache/huggingface/transformers/8ceef1c800b05474d2b470c6dac1644ac368e78b997569934c1d9e48989fa09c.9777c1408575043925e0a5a63c1144e4c19e67cc033b9c85069a11e52ea4bc2d.lock\u001b[0m\n",
      "\u001b[34m2022-01-24 21:51:33,002 - filelock - INFO - Lock 140550875830480 released on /root/.cache/huggingface/transformers/8ceef1c800b05474d2b470c6dac1644ac368e78b997569934c1d9e48989fa09c.9777c1408575043925e0a5a63c1144e4c19e67cc033b9c85069a11e52ea4bc2d.lock\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:37.753 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:37.897 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:37.898 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:37.898 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:37.899 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:37.900 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.065 algo-1:26 INFO hook.py:591] name:module.mpnet.embeddings.word_embeddings.weight count_params:23444736\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.embeddings.position_embeddings.weight count_params:394752\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.066 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.067 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.068 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.069 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.070 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.071 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.072 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.073 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.074 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.075 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.076 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.077 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.078 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.079 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.080 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.081 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.082 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.083 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.084 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.085 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.086 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.mpnet.encoder.relative_attention_bias.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.classifier.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.classifier.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.classifier.out_proj.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:591] name:module.classifier.out_proj.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:593] Total Trainable Params: 109488002\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.087 algo-1:26 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-01-24 21:51:38.090 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mNCCL version 2.7.8+cuda11.0\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.6860125660896301, 'eval_accuracy': 0.557625, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 7.2155, 'eval_samples_per_second': 1108.726, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.6718617677688599, 'eval_accuracy': 0.58225, 'eval_f1': 0.22959889349930843, 'eval_precision': 0.623279098873592, 'eval_recall': 0.1407177168691721, 'eval_runtime': 7.2839, 'eval_samples_per_second': 1098.313, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.3412327170372009, 'eval_accuracy': 0.869, 'eval_f1': 0.8445565114209433, 'eval_precision': 0.888854199188261, 'eval_recall': 0.8044645380050862, 'eval_runtime': 7.3638, 'eval_samples_per_second': 1086.395, 'epoch': 2.99}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22034403681755066, 'eval_accuracy': 0.923125, 'eval_f1': 0.9163151449176759, 'eval_precision': 0.8837270341207349, 'eval_recall': 0.9513987001977959, 'eval_runtime': 7.2018, 'eval_samples_per_second': 1110.829, 'epoch': 3.99}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 1122.8698, 'train_samples_per_second': 0.171, 'epoch': 3.99}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/594 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 594/594 [00:00<00:00, 708kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]#015Downloading:   1%|          | 4.57M/438M [00:00<00:09, 45.7MB/s]#015Downloading:   2%|▏         | 9.17M/438M [00:00<00:09, 45.8MB/s]#015Downloading:   3%|▎         | 13.5M/438M [00:00<00:09, 45.2MB/s]#015Downloading:   4%|▍         | 18.3M/438M [00:00<00:09, 45.9MB/s]#015Downloading:   5%|▌         | 23.1M/438M [00:00<00:08, 46.6MB/s]#015Downloading:   6%|▋         | 28.0M/438M [00:00<00:08, 47.1MB/s]#015Downloading:   8%|▊         | 32.9M/438M [00:00<00:08, 47.6MB/s]#015Downloading:   9%|▊         | 37.7M/438M [00:00<00:08, 47.7MB/s]#015Downloading:  10%|▉         | 42.5M/438M [00:00<00:08, 47.9MB/s]#015Downloading:  11%|█         | 47.4M/438M [00:01<00:08, 48.2MB/s]#015Downloading:  12%|█▏        | 52.3M/438M [00:01<00:07, 48.6MB/s]#015Downloading:  13%|█▎        | 57.3M/438M [00:01<00:07, 48.8MB/s]#015Downloading:  14%|█▍        | 62.2M/438M [00:01<00:07, 49.0MB/s]#015Downloading:  15%|█▌        | 67.1M/438M [00:01<00:07, 48.9MB/s]#015Downloading:  16%|█▋        | 72.1M/438M [00:01<00:07, 49.1MB/s]#015Downloading:  18%|█▊        | 77.0M/438M [00:01<00:07, 49.2MB/s]#015Downloading:  19%|█▊        | 81.9M/438M [00:01<00:07, 49.2MB/s]#015Downloading:  20%|█▉        | 86.9M/438M [00:01<00:07, 49.2MB/s]#015Downloading:  21%|██        | 91.8M/438M [00:01<00:07, 49.3MB/s]#015Downloading:  22%|██▏       | 96.8M/438M [00:02<00:06, 49.4MB/s]#015Downloading:  23%|██▎       | 102M/438M [00:02<00:06, 49.5MB/s] #015Downloading:  24%|██▍       | 107M/438M [00:02<00:06, 49.5MB/s]#015Downloading:  26%|██▌       | 112M/438M [00:02<00:06, 49.7MB/s]#015Downloading:  27%|██▋       | 117M/438M [00:02<00:06, 49.7MB/s]#015Downloading:  28%|██▊       | 122M/438M [00:02<00:06, 49.7MB/s]#015Downloading:  29%|██▉       | 127M/438M [00:02<00:06, 49.7MB/s]#015Downloading:  30%|███       | 132M/438M [00:02<00:06, 49.8MB/s]#015Downloading:  31%|███       | 137M/438M [00:02<00:06, 49.7MB/s]#015Downloading:  32%|███▏      | 142M/438M [00:02<00:05, 49.7MB/s]#015Downloading:  33%|███▎      | 147M/438M [00:03<00:05, 49.8MB/s]#015Downloading:  35%|███▍      | 152M/438M [00:03<00:05, 49.8MB/s]#015Downloading:  36%|███▌      | 157M/438M [00:03<00:05, 49.8MB/s]#015Downloading:  37%|███▋      | 162M/438M [00:03<00:05, 49.8MB/s]#015Downloading:  38%|███▊      | 166M/438M [00:03<00:05, 49.8MB/s]#015Downloading:  39%|███▉      | 172M/438M [00:03<00:05, 49.9MB/s]#015Downloading:  40%|████      | 177M/438M [00:03<00:05, 49.9MB/s]#015Downloading:  41%|████▏     | 181M/438M [00:03<00:05, 49.8MB/s]#015Downloading:  43%|████▎     | 186M/438M [00:03<00:05, 49.7MB/s]#015Downloading:  44%|████▎     | 191M/438M [00:03<00:04, 49.6MB/s]#015Downloading:  45%|████▍     | 196M/438M [00:04<00:04, 49.6MB/s]#015Downloading:  46%|████▌     | 201M/438M [00:04<00:04, 49.7MB/s]#015Downloading:  47%|████▋     | 206M/438M [00:04<00:05, 44.2MB/s]#015Downloading:  48%|████▊     | 211M/438M [00:04<00:05, 43.9MB/s]#015Downloading:  49%|████▉     | 216M/438M [00:04<00:04, 45.4MB/s]#015Downloading:  50%|█████     | 221M/438M [00:04<00:04, 46.6MB/s]#015Downloading:  52%|█████▏    | 226M/438M [00:04<00:04, 47.5MB/s]#015Downloading:  53%|█████▎    | 231M/438M [00:04<00:04, 47.9MB/s]#015Downloading:  54%|█████▍    | 236M/438M [00:04<00:04, 48.5MB/s]#015Downloading:  55%|█████▍    | 241M/438M [00:04<00:04, 48.9MB/s]#015Downloading:  56%|█████▌    | 246M/438M [00:05<00:03, 49.2MB/s]#015Downloading:  57%|█████▋    | 251M/438M [00:05<00:03, 49.3MB/s]#015Downloading:  58%|█████▊    | 256M/438M [00:05<00:03, 50.8MB/s]#015Downloading:  60%|█████▉    | 262M/438M [00:05<00:03, 53.0MB/s]#015Downloading:  61%|██████    | 268M/438M [00:05<00:03, 54.6MB/s]#015Downloading:  62%|██████▏   | 274M/438M [00:05<00:02, 55.8MB/s]#015Downloading:  64%|██████▍   | 280M/438M [00:05<00:02, 56.8MB/s]#015Downloading:  65%|██████▌   | 286M/438M [00:05<00:02, 57.4MB/s]#015Downloading:  67%|██████▋   | 291M/438M [00:05<00:02, 57.7MB/s]#015Downloading:  68%|██████▊   | 297M/438M [00:05<00:02, 58.1MB/s]#015Downloading:  69%|██████▉   | 303M/438M [00:06<00:02, 58.5MB/s]#015Downloading:  71%|███████   | 309M/438M [00:06<00:02, 58.9MB/s]#015Downloading:  72%|███████▏  | 315M/438M [00:06<00:02, 59.1MB/s]#015Downloading:  73%|███████▎  | 321M/438M [00:06<00:01, 59.2MB/s]#015Downloading:  75%|███████▍  | 327M/438M [00:06<00:01, 59.3MB/s]#015Downloading:  76%|███████▌  | 333M/438M [00:06<00:01, 59.3MB/s]#015Downloading:  77%|███████▋  | 339M/438M [00:06<00:01, 59.3MB/s]#015Downloading:  79%|███████▊  | 345M/438M [00:06<00:01, 59.3MB/s]#015Downloading:  80%|████████  | 351M/438M [00:06<00:01, 59.3MB/s]#015Downloading:  81%|████████▏ | 357M/438M [00:06<00:01, 58.8MB/s]#015Downloading:  83%|████████▎ | 363M/438M [00:07<00:01, 59.2MB/s]#015Downloading:  84%|████████▍ | 369M/438M [00:07<00:01, 59.3MB/s]#015Downloading:  86%|████████▌ | 375M/438M [00:07<00:01, 59.4MB/s]#015Downloading:  87%|████████▋ | 381M/438M [00:07<00:00, 59.4MB/s]#015Downloading:  88%|████████▊ | 387M/438M [00:07<00:00, 59.5MB/s]#015Downloading:  90%|████████▉ | 393M/438M [00:07<00:00, 59.5MB/s]#015Downloading:  91%|█████████ | 398M/438M [00:07<00:00, 59.3MB/s]#015Downloading:  92%|█████████▏| 404M/438M [00:07<00:00, 59.3MB/s]#015Downloading:  94%|█████████▎| 410M/438M [00:07<00:00, 58.2MB/s]#015Downloading:  95%|█████████▌| 416M/438M [00:07<00:00, 58.1MB/s]#015Downloading:  96%|█████████▋| 422M/438M [00:08<00:00, 58.5MB/s]#015Downloading:  98%|█████████▊| 428M/438M [00:08<00:00, 58.8MB/s]#015Downloading:  99%|█████████▉| 434M/438M [00:08<00:00, 59.0MB/s]#015Downloading: 100%|██████████| 438M/438M [00:08<00:00, 52.6MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at sentence-transformers/paraphrase-mpnet-base-v2 were not used when initializing MPNetForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 41.6MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 466k/466k [00:00<00:00, 45.2MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 239/239 [00:00<00:00, 327kB/s]\u001b[0m\n",
      "\u001b[34m2022-01-24 22:10:30,596 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.19k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 1.19k/1.19k [00:00<00:00, 1.52MB/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/192 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\u001b[0m\n",
      "\u001b[34m#015  1%|          | 1/192 [00:13<43:00, 13.51s/it]#015  1%|          | 2/192 [00:19<35:10, 11.11s/it]#015  2%|▏         | 3/192 [00:24<29:52,  9.48s/it]#015  2%|▏         | 4/192 [00:30<26:05,  8.33s/it]#015  3%|▎         | 5/192 [00:35<23:18,  7.48s/it]#015  3%|▎         | 6/192 [00:41<21:21,  6.89s/it]#015  4%|▎         | 7/192 [00:46<19:58,  6.48s/it]#015  4%|▍         | 8/192 [00:52<18:55,  6.17s/it]#015  5%|▍         | 9/192 [00:57<18:13,  5.97s/it]#015  5%|▌         | 10/192 [01:03<17:39,  5.82s/it]#015  6%|▌         | 11/192 [01:08<17:19,  5.74s/it]#015  6%|▋         | 12/192 [01:14<16:58,  5.66s/it]#015  7%|▋         | 13/192 [01:19<16:44,  5.61s/it]#015  7%|▋         | 14/192 [01:25<16:34,  5.59s/it]#015  8%|▊         | 15/192 [01:30<16:31,  5.60s/it]#015  8%|▊         | 16/192 [01:36<16:20,  5.57s/it]#015  9%|▉         | 17/192 [01:42<16:11,  5.55s/it]#015  9%|▉         | 18/192 [01:47<16:04,  5.55s/it]#015 10%|▉         | 19/192 [01:53<15:59,  5.54s/it]#015 10%|█         | 20/192 [01:58<15:56,  5.56s/it]#015 11%|█         | 21/192 [02:04<15:51,  5.56s/it]#015 11%|█▏        | 22/192 [02:09<15:42,  5.55s/it]#015 12%|█▏        | 23/192 [02:15<15:38,  5.55s/it]#015 12%|█▎        | 24/192 [02:20<15:34,  5.56s/it]#015 13%|█▎        | 25/192 [02:26<15:28,  5.56s/it]#015 14%|█▎        | 26/192 [02:32<15:22,  5.56s/it]#015 14%|█▍        | 27/192 [02:37<15:16,  5.56s/it]#015 15%|█▍        | 28/192 [02:43<15:13,  5.57s/it]#015 15%|█▌        | 29/192 [02:48<15:07,  5.57s/it]#015 16%|█▌        | 30/192 [02:54<14:56,  5.53s/it]#015 16%|█▌        | 31/192 [02:59<14:54,  5.56s/it]#015 17%|█▋        | 32/192 [03:05<14:48,  5.55s/it]#015 17%|█▋        | 33/192 [03:10<14:39,  5.53s/it]#015 18%|█▊        | 34/192 [03:16<14:33,  5.53s/it]#015 18%|█▊        | 35/192 [03:21<14:30,  5.55s/it]#015 19%|█▉        | 36/192 [03:27<14:26,  5.55s/it]#015 19%|█▉        | 37/192 [03:33<14:23,  5.57s/it]#015 20%|█▉        | 38/192 [03:38<14:13,  5.54s/it]#015 20%|██        | 39/192 [03:44<14:06,  5.53s/it]#015 21%|██        | 40/192 [03:49<13:59,  5.52s/it]#015 21%|██▏       | 41/192 [03:55<13:54,  5.53s/it]#015 22%|██▏       | 42/192 [04:00<13:48,  5.53s/it]#015 22%|██▏       | 43/192 [04:06<13:46,  5.55s/it]#015 23%|██▎       | 44/192 [04:11<13:41,  5.55s/it]#015 23%|██▎       | 45/192 [04:17<13:37,  5.56s/it]#015 24%|██▍       | 46/192 [04:22<13:29,  5.54s/it]#015 24%|██▍       | 47/192 [04:28<13:30,  5.59s/it]#015 25%|██▌       | 48/192 [04:34<13:20,  5.56s/it]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|▋         | 2/32 [00:00<00:03,  9.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 3/32 [00:00<00:04,  7.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|█▎        | 4/32 [00:00<00:04,  6.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▌        | 5/32 [00:00<00:04,  5.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|█▉        | 6/32 [00:01<00:05,  5.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 7/32 [00:01<00:05,  4.97it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 8/32 [00:01<00:04,  4.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|██▊       | 9/32 [00:01<00:04,  4.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███▏      | 10/32 [00:02<00:05,  4.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|███▍      | 11/32 [00:02<00:04,  4.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 12/32 [00:02<00:04,  4.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|████      | 13/32 [00:02<00:04,  4.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▍     | 14/32 [00:02<00:04,  4.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 15/32 [00:03<00:03,  4.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 16/32 [00:03<00:03,  4.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 17/32 [00:03<00:03,  4.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 18/32 [00:03<00:03,  4.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|█████▉    | 19/32 [00:04<00:02,  4.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▎   | 20/32 [00:04<00:02,  4.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|██████▌   | 21/32 [00:04<00:02,  4.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 22/32 [00:04<00:02,  4.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|███████▏  | 23/32 [00:05<00:02,  4.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▌  | 24/32 [00:05<00:01,  4.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 25/32 [00:05<00:01,  4.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|████████▏ | 26/32 [00:05<00:01,  4.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▍ | 27/32 [00:05<00:01,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|████████▊ | 28/32 [00:06<00:00,  4.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 29/32 [00:06<00:00,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|█████████▍| 30/32 [00:06<00:00,  4.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|█████████▋| 31/32 [00:06<00:00,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:06<00:00,  4.61it/s]#033[A/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\u001b[0m\n",
      "\u001b[34m#015                                                #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 25%|██▌       | 48/192 [04:42<13:20,  5.56s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:06<00:00,  4.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\u001b[0m\n",
      "\u001b[34m#015 26%|██▌       | 49/192 [04:51<21:36,  9.07s/it]#015 26%|██▌       | 50/192 [04:56<18:52,  7.97s/it]#015 27%|██▋       | 51/192 [05:02<17:00,  7.24s/it]#015 27%|██▋       | 52/192 [05:07<15:43,  6.74s/it]#015 28%|██▊       | 53/192 [05:13<14:43,  6.36s/it]#015 28%|██▊       | 54/192 [05:18<14:08,  6.15s/it]#015 29%|██▊       | 55/192 [05:24<13:39,  5.98s/it]#015 29%|██▉       | 56/192 [05:30<13:19,  5.88s/it]#015 30%|██▉       | 57/192 [05:35<12:54,  5.74s/it]#015 30%|███       | 58/192 [05:41<12:45,  5.71s/it]#015 31%|███       | 59/192 [05:46<12:32,  5.66s/it]#015 31%|███▏      | 60/192 [05:52<12:23,  5.63s/it]#015 32%|███▏      | 61/192 [05:57<12:15,  5.61s/it]#015 32%|███▏      | 62/192 [06:03<12:05,  5.58s/it]#015 33%|███▎      | 63/192 [06:08<11:52,  5.52s/it]#015 33%|███▎      | 64/192 [06:14<11:41,  5.48s/it]#015 34%|███▍      | 65/192 [06:19<11:40,  5.51s/it]#015 34%|███▍      | 66/192 [06:25<11:35,  5.52s/it]#015 35%|███▍      | 67/192 [06:31<11:37,  5.58s/it]#015 35%|███▌      | 68/192 [06:36<11:30,  5.57s/it]#015 36%|███▌      | 69/192 [06:42<11:25,  5.58s/it]#015 36%|███▋      | 70/192 [06:47<11:14,  5.53s/it]#015 37%|███▋      | 71/192 [06:53<11:07,  5.52s/it]#015 38%|███▊      | 72/192 [06:58<10:59,  5.50s/it]#015 38%|███▊      | 73/192 [07:04<10:56,  5.52s/it]#015 39%|███▊      | 74/192 [07:09<10:49,  5.50s/it]#015 39%|███▉      | 75/192 [07:15<10:43,  5.50s/it]#015 40%|███▉      | 76/192 [07:20<10:40,  5.53s/it]#015 40%|████      | 77/192 [07:26<10:35,  5.53s/it]#015 41%|████      | 78/192 [07:31<10:31,  5.54s/it]#015 41%|████      | 79/192 [07:37<10:23,  5.51s/it]#015 42%|████▏     | 80/192 [07:42<10:17,  5.51s/it]#015 42%|████▏     | 81/192 [07:48<10:08,  5.48s/it]#015 43%|████▎     | 82/192 [07:53<10:05,  5.50s/it]#015 43%|████▎     | 83/192 [07:59<09:58,  5.49s/it]#015 44%|████▍     | 84/192 [08:04<09:54,  5.50s/it]#015 44%|████▍     | 85/192 [08:10<09:48,  5.50s/it]#015 45%|████▍     | 86/192 [08:15<09:43,  5.50s/it]#015 45%|████▌     | 87/192 [08:21<09:36,  5.49s/it]#015 46%|████▌     | 88/192 [08:26<09:32,  5.50s/it]#015 46%|████▋     | 89/192 [08:32<09:30,  5.54s/it]#015 47%|████▋     | 90/192 [08:37<09:26,  5.55s/it]#015 47%|████▋     | 91/192 [08:43<09:19,  5.54s/it]#015 48%|████▊     | 92/192 [08:48<09:11,  5.52s/it]#015 48%|████▊     | 93/192 [08:54<09:07,  5.53s/it]#015 49%|████▉     | 94/192 [08:59<09:00,  5.51s/it]#015 49%|████▉     | 95/192 [09:05<08:54,  5.51s/it]#015 50%|█████     | 96/192 [09:10<08:47,  5.49s/it]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|▋         | 2/32 [00:00<00:03,  9.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 3/32 [00:00<00:04,  6.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|█▎        | 4/32 [00:00<00:04,  5.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▌        | 5/32 [00:00<00:05,  5.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|█▉        | 6/32 [00:01<00:05,  4.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 7/32 [00:01<00:05,  4.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 8/32 [00:01<00:05,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|██▊       | 9/32 [00:01<00:05,  4.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███▏      | 10/32 [00:02<00:04,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|███▍      | 11/32 [00:02<00:04,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 12/32 [00:02<00:04,  4.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|████      | 13/32 [00:02<00:04,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▍     | 14/32 [00:02<00:03,  4.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 15/32 [00:03<00:03,  4.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 16/32 [00:03<00:03,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 17/32 [00:03<00:03,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 18/32 [00:03<00:03,  4.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|█████▉    | 19/32 [00:04<00:02,  4.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▎   | 20/32 [00:04<00:02,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|██████▌   | 21/32 [00:04<00:02,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 22/32 [00:04<00:02,  4.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|███████▏  | 23/32 [00:05<00:02,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▌  | 24/32 [00:05<00:01,  4.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 25/32 [00:05<00:01,  4.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|████████▏ | 26/32 [00:05<00:01,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▍ | 27/32 [00:05<00:01,  4.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|████████▊ | 28/32 [00:06<00:00,  4.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 29/32 [00:06<00:00,  4.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|█████████▍| 30/32 [00:06<00:00,  4.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|█████████▋| 31/32 [00:06<00:00,  4.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:07<00:00,  4.52it/s]#033[A#015                                                #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 50%|█████     | 96/192 [09:19<08:47,  5.49s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:07<00:00,  4.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\u001b[0m\n",
      "\u001b[34m#015 51%|█████     | 97/192 [09:28<14:22,  9.08s/it]#015 51%|█████     | 98/192 [09:33<12:35,  8.04s/it]#015 52%|█████▏    | 99/192 [09:39<11:18,  7.30s/it]#015 52%|█████▏    | 100/192 [09:45<10:24,  6.78s/it]#015 53%|█████▎    | 101/192 [09:50<09:43,  6.41s/it]#015 53%|█████▎    | 102/192 [09:56<09:17,  6.19s/it]#015 54%|█████▎    | 103/192 [10:01<08:54,  6.01s/it]#015 54%|█████▍    | 104/192 [10:07<08:35,  5.85s/it]#015 55%|█████▍    | 105/192 [10:12<08:23,  5.78s/it]#015 55%|█████▌    | 106/192 [10:18<08:12,  5.72s/it]#015 56%|█████▌    | 107/192 [10:24<08:02,  5.68s/it]#015 56%|█████▋    | 108/192 [10:29<07:56,  5.67s/it]#015 57%|█████▋    | 109/192 [10:35<07:50,  5.67s/it]#015 57%|█████▋    | 110/192 [10:40<07:40,  5.62s/it]#015 58%|█████▊    | 111/192 [10:46<07:34,  5.61s/it]#015 58%|█████▊    | 112/192 [10:52<07:27,  5.60s/it]#015 59%|█████▉    | 113/192 [10:57<07:23,  5.61s/it]#015 59%|█████▉    | 114/192 [11:03<07:13,  5.56s/it]#015 60%|█████▉    | 115/192 [11:08<07:08,  5.56s/it]#015 60%|██████    | 116/192 [11:14<07:03,  5.57s/it]#015 61%|██████    | 117/192 [11:19<06:56,  5.55s/it]#015 61%|██████▏   | 118/192 [11:25<06:53,  5.58s/it]#015 62%|██████▏   | 119/192 [11:31<06:49,  5.61s/it]#015 62%|██████▎   | 120/192 [11:36<06:43,  5.60s/it]#015 63%|██████▎   | 121/192 [11:42<06:37,  5.59s/it]#015 64%|██████▎   | 122/192 [11:48<06:33,  5.62s/it]#015 64%|██████▍   | 123/192 [11:53<06:26,  5.60s/it]#015 65%|██████▍   | 124/192 [11:59<06:19,  5.59s/it]#015 65%|██████▌   | 125/192 [12:04<06:13,  5.58s/it]#015 66%|██████▌   | 126/192 [12:10<06:07,  5.57s/it]#015 66%|██████▌   | 127/192 [12:15<06:03,  5.59s/it]#015 67%|██████▋   | 128/192 [12:21<05:56,  5.57s/it]#015 67%|██████▋   | 129/192 [12:27<05:53,  5.61s/it]#015 68%|██████▊   | 130/192 [12:32<05:47,  5.61s/it]#015 68%|██████▊   | 131/192 [12:38<05:42,  5.62s/it]#015 69%|██████▉   | 132/192 [12:43<05:34,  5.57s/it]#015 69%|██████▉   | 133/192 [12:49<05:30,  5.61s/it]#015 70%|██████▉   | 134/192 [12:55<05:24,  5.59s/it]#015 70%|███████   | 135/192 [13:00<05:19,  5.61s/it]#015 71%|███████   | 136/192 [13:06<05:13,  5.59s/it]#015 71%|███████▏  | 137/192 [13:11<05:08,  5.61s/it]#015 72%|███████▏  | 138/192 [13:17<05:03,  5.62s/it]#015 72%|███████▏  | 139/192 [13:23<04:57,  5.60s/it]#015 73%|███████▎  | 140/192 [13:28<04:54,  5.66s/it]#015 73%|███████▎  | 141/192 [13:34<04:47,  5.63s/it]#015 74%|███████▍  | 142/192 [13:40<04:41,  5.64s/it]#015 74%|███████▍  | 143/192 [13:45<04:35,  5.62s/it]#015 75%|███████▌  | 144/192 [13:51<04:30,  5.63s/it]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|▋         | 2/32 [00:00<00:03,  8.93it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 3/32 [00:00<00:04,  6.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|█▎        | 4/32 [00:00<00:04,  5.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▌        | 5/32 [00:00<00:05,  5.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|█▉        | 6/32 [00:01<00:05,  4.63it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 7/32 [00:01<00:05,  4.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 8/32 [00:01<00:05,  4.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|██▊       | 9/32 [00:01<00:05,  4.55it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███▏      | 10/32 [00:02<00:04,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|███▍      | 11/32 [00:02<00:04,  4.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 12/32 [00:02<00:04,  4.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|████      | 13/32 [00:02<00:04,  4.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▍     | 14/32 [00:02<00:03,  4.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 15/32 [00:03<00:03,  4.42it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 16/32 [00:03<00:03,  4.45it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 17/32 [00:03<00:03,  4.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 18/32 [00:03<00:03,  4.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|█████▉    | 19/32 [00:04<00:03,  4.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▎   | 20/32 [00:04<00:02,  4.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|██████▌   | 21/32 [00:04<00:02,  4.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 22/32 [00:04<00:02,  4.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|███████▏  | 23/32 [00:05<00:02,  4.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▌  | 24/32 [00:05<00:01,  4.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 25/32 [00:05<00:01,  4.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|████████▏ | 26/32 [00:05<00:01,  4.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▍ | 27/32 [00:05<00:01,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|████████▊ | 28/32 [00:06<00:00,  4.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 29/32 [00:06<00:00,  4.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|█████████▍| 30/32 [00:06<00:00,  4.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|█████████▋| 31/32 [00:06<00:00,  4.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:07<00:00,  4.51it/s]#033[A#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 75%|███████▌  | 144/192 [14:00<04:30,  5.63s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:07<00:00,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\u001b[0m\n",
      "\u001b[34m#015 76%|███████▌  | 145/192 [14:08<07:10,  9.15s/it]#015 76%|███████▌  | 146/192 [14:14<06:12,  8.10s/it]#015 77%|███████▋  | 147/192 [14:19<05:30,  7.34s/it]#015 77%|███████▋  | 148/192 [14:25<04:59,  6.80s/it]#015 78%|███████▊  | 149/192 [14:31<04:37,  6.46s/it]#015 78%|███████▊  | 150/192 [14:36<04:21,  6.24s/it]#015 79%|███████▊  | 151/192 [14:42<04:09,  6.08s/it]#015 79%|███████▉  | 152/192 [14:48<03:56,  5.92s/it]#015 80%|███████▉  | 153/192 [14:53<03:47,  5.82s/it]#015 80%|████████  | 154/192 [14:59<03:38,  5.75s/it]#015 81%|████████  | 155/192 [15:04<03:30,  5.70s/it]#015 81%|████████▏ | 156/192 [15:10<03:23,  5.65s/it]#015 82%|████████▏ | 157/192 [15:16<03:17,  5.64s/it]#015 82%|████████▏ | 158/192 [15:21<03:10,  5.62s/it]#015 83%|████████▎ | 159/192 [15:27<03:07,  5.67s/it]#015 83%|████████▎ | 160/192 [15:33<03:01,  5.66s/it]#015 84%|████████▍ | 161/192 [15:38<02:55,  5.66s/it]#015 84%|████████▍ | 162/192 [15:44<02:48,  5.63s/it]#015 85%|████████▍ | 163/192 [15:49<02:42,  5.62s/it]#015 85%|████████▌ | 164/192 [15:55<02:37,  5.61s/it]#015 86%|████████▌ | 165/192 [16:01<02:31,  5.62s/it]#015 86%|████████▋ | 166/192 [16:06<02:26,  5.62s/it]#015 87%|████████▋ | 167/192 [16:12<02:19,  5.60s/it]#015 88%|████████▊ | 168/192 [16:17<02:13,  5.58s/it]#015 88%|████████▊ | 169/192 [16:23<02:08,  5.60s/it]#015 89%|████████▊ | 170/192 [16:29<02:03,  5.63s/it]#015 89%|████████▉ | 171/192 [16:34<01:58,  5.63s/it]#015 90%|████████▉ | 172/192 [16:40<01:53,  5.67s/it]#015 90%|█████████ | 173/192 [16:46<01:47,  5.65s/it]#015 91%|█████████ | 174/192 [16:51<01:41,  5.63s/it]#015 91%|█████████ | 175/192 [16:57<01:35,  5.62s/it]#015 92%|█████████▏| 176/192 [17:02<01:29,  5.61s/it]#015 92%|█████████▏| 177/192 [17:08<01:24,  5.62s/it]#015 93%|█████████▎| 178/192 [17:14<01:18,  5.58s/it]#015 93%|█████████▎| 179/192 [17:19<01:12,  5.61s/it]#015 94%|█████████▍| 180/192 [17:25<01:07,  5.62s/it]#015 94%|█████████▍| 181/192 [17:30<01:01,  5.63s/it]#015 95%|█████████▍| 182/192 [17:36<00:56,  5.61s/it]#015 95%|█████████▌| 183/192 [17:42<00:50,  5.61s/it]#015 96%|█████████▌| 184/192 [17:47<00:44,  5.60s/it]#015 96%|█████████▋| 185/192 [17:53<00:39,  5.58s/it]#015 97%|█████████▋| 186/192 [17:58<00:33,  5.58s/it]#015 97%|█████████▋| 187/192 [18:04<00:27,  5.56s/it]#015 98%|█████████▊| 188/192 [18:09<00:22,  5.55s/it]#015 98%|█████████▊| 189/192 [18:15<00:16,  5.55s/it]#015 99%|█████████▉| 190/192 [18:21<00:11,  5.59s/it]#015 99%|█████████▉| 191/192 [18:26<00:05,  5.57s/it]#015100%|██████████| 192/192 [18:32<00:00,  5.59s/it]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|▋         | 2/32 [00:00<00:03,  9.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 3/32 [00:00<00:04,  7.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|█▎        | 4/32 [00:00<00:04,  5.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▌        | 5/32 [00:00<00:05,  5.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 19%|█▉        | 6/32 [00:01<00:05,  5.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 7/32 [00:01<00:05,  4.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 8/32 [00:01<00:04,  4.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|██▊       | 9/32 [00:01<00:04,  4.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███▏      | 10/32 [00:02<00:05,  4.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|███▍      | 11/32 [00:02<00:04,  4.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 12/32 [00:02<00:04,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|████      | 13/32 [00:02<00:04,  4.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▍     | 14/32 [00:02<00:03,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 15/32 [00:03<00:03,  4.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 16/32 [00:03<00:03,  4.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 17/32 [00:03<00:03,  4.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 18/32 [00:03<00:03,  4.59it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|█████▉    | 19/32 [00:04<00:02,  4.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▎   | 20/32 [00:04<00:02,  4.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|██████▌   | 21/32 [00:04<00:02,  4.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 22/32 [00:04<00:02,  4.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|███████▏  | 23/32 [00:04<00:02,  4.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▌  | 24/32 [00:05<00:01,  4.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 25/32 [00:05<00:01,  4.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 81%|████████▏ | 26/32 [00:05<00:01,  4.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▍ | 27/32 [00:05<00:01,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|████████▊ | 28/32 [00:06<00:00,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 29/32 [00:06<00:00,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|█████████▍| 30/32 [00:06<00:00,  4.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|█████████▋| 31/32 [00:06<00:00,  4.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:06<00:00,  4.63it/s]#033[A#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|██████████| 192/192 [18:39<00:00,  5.59s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:06<00:00,  4.63it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A#015                                                 #015#015100%|██████████| 192/192 [18:42<00:00,  5.59s/it]#015100%|██████████| 192/192 [18:42<00:00,  5.85s/it]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?it/s]#015  6%|▋         | 2/32 [00:00<00:03,  9.23it/s]#015  9%|▉         | 3/32 [00:00<00:04,  7.05it/s]#015 12%|█▎        | 4/32 [00:00<00:04,  5.79it/s]#015 16%|█▌        | 5/32 [00:00<00:05,  5.26it/s]#015 19%|█▉        | 6/32 [00:01<00:05,  4.99it/s]#015 22%|██▏       | 7/32 [00:01<00:05,  4.85it/s]#015 25%|██▌       | 8/32 [00:01<00:05,  4.75it/s]#015 28%|██▊       | 9/32 [00:01<00:04,  4.70it/s]#015 31%|███▏      | 10/32 [00:02<00:04,  4.62it/s]#015 34%|███▍      | 11/32 [00:02<00:05,  4.13it/s]#015 38%|███▊      | 12/32 [00:02<00:04,  4.24it/s]#015 41%|████      | 13/32 [00:02<00:04,  4.31it/s]#015 44%|████▍     | 14/32 [00:02<00:04,  4.36it/s]#015 47%|████▋     | 15/32 [00:03<00:03,  4.38it/s]#015 50%|█████     | 16/32 [00:03<00:03,  4.41it/s]#015 53%|█████▎    | 17/32 [00:03<00:03,  4.42it/s]#015 56%|█████▋    | 18/32 [00:03<00:03,  4.45it/s]#015 59%|█████▉    | 19/32 [00:04<00:02,  4.46it/s]#015 62%|██████▎   | 20/32 [00:04<00:02,  4.43it/s]#015 66%|██████▌   | 21/32 [00:04<00:02,  4.43it/s]#015 69%|██████▉   | 22/32 [00:04<00:02,  4.46it/s]#015 72%|███████▏  | 23/32 [00:05<00:02,  4.06it/s]#015 75%|███████▌  | 24/32 [00:05<00:01,  4.19it/s]#015 78%|███████▊  | 25/32 [00:05<00:01,  4.28it/s]#015 81%|████████▏ | 26/32 [00:05<00:01,  4.35it/s]#015 84%|████████▍ | 27/32 [00:05<00:01,  4.41it/s]#015 88%|████████▊ | 28/32 [00:06<00:00,  4.39it/s]#015 91%|█████████ | 29/32 [00:06<00:00,  4.37it/s]#015 94%|█████████▍| 30/32 [00:06<00:00,  4.43it/s]#015 97%|█████████▋| 31/32 [00:06<00:00,  4.41it/s]#015100%|██████████| 32/32 [00:07<00:00,  4.62it/s]#015100%|██████████| 32/32 [00:07<00:00,  4.52it/s]\u001b[0m\n",
      "\n",
      "2022-01-24 22:11:35 Uploading - Uploading generated training model\n",
      "2022-01-24 22:15:12 Completed - Training job completed\n",
      "Training seconds: 1630\n",
      "Billable seconds: 1630\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Begin fine-tuning\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': val_input_path}, \n",
    "                          wait=True, \n",
    "                          job_name='sm-sts-blog-{}'.format(int(time.time())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6714b44",
   "metadata": {},
   "source": [
    "![](./img/sagemaker-training-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634deb7",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71ef66",
   "metadata": {},
   "source": [
    "To deploy the trained model to an endpoint, we call the `deploy()` method on the HuggingFace estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3ade246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_estimator.deploy(initial_instance_count=1,\n",
    "                                         instance_type=\"ml.g4dn.xlarge\", \n",
    "                                         endpoint_name=\"sts-sbert-paws\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cafb7a",
   "metadata": {},
   "source": [
    "**Optional: Alternativel, we can also load the fine-tuned model from s3, if one has been trained previously.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment out cells below after final review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7785a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# sm_client = boto3.client('sagemaker')\n",
    "# bucket_name = 'sts-sbert-paws-blog'\n",
    "# latest_sm_training_job_name = sm_client.list_training_jobs()['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "\n",
    "# S3_PATH_TRAINED_MODEL_FILE = 's3://' + bucket_name + '/' + latest_sm_training_job_name + '/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3f9f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recreate the huggingface_model object\n",
    "\n",
    "# from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# huggingface_model = HuggingFaceModel(\n",
    "#     model_data=S3_PATH_TRAINED_MODEL_FILE,\n",
    "#     role=role,\n",
    "#     transformers_version='4.6.1',\n",
    "#     pytorch_version='1.7.1',\n",
    "#     py_version='py36',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fbd61e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "# predictor = huggingface_model.deploy(initial_instance_count=1,\n",
    "#                                      instance_type='ml.g4dn.xlarge', \n",
    "#                                      endpoint_name='sts-sbert-paws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421cd9b",
   "metadata": {},
   "source": [
    "Other scenarios to deploy a model to a SageMaker endpoint include - 1) from a model stored in the [Hugging Face Hub](https://huggingface.co/models) and 2) by using a custom inference container. For more information on these methods refer to [Announcing managed inference for Hugging Face models in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc2ed1",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647a6d6",
   "metadata": {},
   "source": [
    "Once the model is deployed, we can send observations from the unseen test dataset - `df_test` to the endpoint, to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe53fd6",
   "metadata": {},
   "source": [
    "Let's select a few sentences from the test dataset and send it to the endpoint for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae534ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Mark Twain ( 11 August 1798 – 24 March 1847 ) was the father of the author John Marshall Clemens .\n",
      "Sentence 2: John Marshall Clemens ( August 11 , 1798 -- March 24 , 1847 ) was the father of the author Mark Twain .\n",
      "\n",
      "True Label: 0\n",
      "Predicted Label: LABEL_0\n",
      "Prediction Confidence: 0.9666486382484436\n"
     ]
    }
   ],
   "source": [
    "# Re-run this cell to see predictions on alternative sample test inputs\n",
    "\n",
    "import random \n",
    "\n",
    "rand = random.randrange(0, 8000)\n",
    "\n",
    "true_label = dataset_test[rand]['label']\n",
    "sent_1 = dataset_test[rand]['sentence1']\n",
    "sent_2 = dataset_test[rand]['sentence2']\n",
    "\n",
    "sentence_pair = {\"inputs\": ['[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]']}\n",
    "\n",
    "print('Sentence 1:', sent_1) \n",
    "print('Sentence 2:', sent_2)\n",
    "print()\n",
    "print('True Label:', true_label)\n",
    "print('Predicted Label:', predictor.predict(sentence_pair)[0]['label'])\n",
    "print('Prediction Confidence:', predictor.predict(sentence_pair)[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eed01",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0bca7",
   "metadata": {},
   "source": [
    "Let's apply the fine-tuned model on the whole unseen test set and evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e5a02b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test set records: 8000\n"
     ]
    }
   ],
   "source": [
    "print('Number of test set records:', len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0a1d2947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [02:40<00:00, 50.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "# Inference takes ~5 minutes for all test records using a fine-tuned roberta-large and ml.g4dn.xlarge instance\n",
    "\n",
    "for i in tqdm(range(len(dataset_test))):\n",
    "    true_label = dataset_test[i]['label']\n",
    "    sent_1 = dataset_test[i]['sentence1']\n",
    "    sent_2 = dataset_test[i]['sentence2']\n",
    "    \n",
    "    sentence_pair = {\"inputs\": ['[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]']}\n",
    "    pred = predictor.predict(sentence_pair)\n",
    "    \n",
    "    labels.append(true_label)\n",
    "    preds.append(int(pred[0]['label'].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9d8983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name: sts-sbert-paws-mpnet\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     paraphase       0.93      0.92      0.93      4464\n",
      "not paraphrase       0.90      0.92      0.91      3536\n",
      "\n",
      "      accuracy                           0.92      8000\n",
      "     macro avg       0.92      0.92      0.92      8000\n",
      "  weighted avg       0.92      0.92      0.92      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Endpoint Name:', predictor.endpoint_name)\n",
    "class_names = ['paraphase', 'not paraphrase']\n",
    "print(classification_report(labels, preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f35177",
   "metadata": {},
   "source": [
    "From the test set scores above, we can see roberta-large has a combined f1-score of 93% and performs equally well across both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf16613",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff3dd6",
   "metadata": {},
   "source": [
    "When we are done with the endpoint, we can delete it to save cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80b51ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e122c",
   "metadata": {},
   "source": [
    "# Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765f688",
   "metadata": {},
   "source": [
    "1. [Use Hugging Face with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html)\n",
    "2. [Hugging Face sample notebooks](https://github.com/huggingface/notebooks/tree/master/sagemaker)\n",
    "3. [AWS Blog - AWS and Hugging Face collaborate to simplify and accelerate adoption of Natural Language Processing models](https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-simplify-and-accelerate-adoption-of-natural-language-processing-models/)\n",
    "4. [AWS Blog - Announcing managed inference for Hugging Face models in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/)\n",
    "5. [The Partnership: Amazon SageMaker and Hugging Face](https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face)\n",
    "6. Sarker A, Gonzalez G. Portable automatic text classification for adverse drug reaction detection via multi-corpus training. J Biomed Inform. 2015;53:196-207. doi:10.1016/j.jbi.2014.11.002\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphrase Identification using HuggingFace on SageMaker - Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many customers today deal with use cases where identifying paraphrased text has business value. For example, by identifying sentence paraphrases, a text summarization system could remove redundant information. Another application is to identify plagiarized documents. Here, we will fine-tune a Hugging Face transformer on SageMaker to identify paraphrased sentence pairs in a few, simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and install libraries\n",
    "\n",
    "We will begin by installing the necessary libraries, importing them into the development environment, selecting the appropriate IAM role and the Amazon S3 bucket.\n",
    "\n",
    "Select the latest `conda_pytorch_p38` notebook kernel\n",
    "\n",
    "Install the required libraries from Hugging Face - `transformers` and `datasets`. We'll also ensure that we have the updated version of `SageMaker Python SDK`\n",
    "\n",
    "Documentation on [Installing Transformers](https://huggingface.co/docs/transformers/installation) and [Installing SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you see the following message after executing the pip install cell below, you can safely ignore it, it does not affect the packages and code in this notebook: \"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\n",
    "spacy 3.0.6 requires pydantic<1.8.0,>=1.7.1, but you have pydantic 1.8.2 which is incompatible.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install \"sagemaker\" \"transformers==4.6.1\" \"datasets==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface\n",
    "import sagemaker\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "print(f\"SageMaker Role Arn: {role}\")\n",
    "print(f\"SageMaker - Amazon S3 Bucket: {bucket}\")\n",
    "print(f\"SageMaker Session Region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `PAWS (Paraphrase Adversaries from Word Scrambling)` dataset. The final labled dataset contains pairs that are genreated from both word swapping and back translation methods. All pairs have human judgements on both paraphrasing and fluency and they are also split into `Train/Validation/Test` sections. The `Train` dataset contains a total of 49,401 sentence pairs, while the `Validation` and `Test` datasets contain a total of 8,000 sentence pairs each.\n",
    "\n",
    "![image info](./img/PAWS-dataset-sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, dataset_test = load_dataset(\"paws\", \"labeled_final\", split=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = dataset_train.to_pandas()\n",
    "\n",
    "ax = sns.countplot(x=\"label\", data=df)\n",
    "ax.set_title('Label Count for PAWS Dataset', fontsize=15)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), ha='center', va='top', color='white', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the dataset is slightly imbalanced, a few class imbalance strategies can be applied such as _oversampling_, _undersampling_, _SMOTE_, etc. For the purpose of demonstration, we will not implement these strategies and assume that we have a fairly balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer_and_model_name = 'roberta-large'\n",
    "\n",
    "# Download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_and_model_name)\n",
    "\n",
    "# Tokenizer helper function\n",
    "def tokenize(batch, max_len=128):\n",
    "    return tokenizer(batch['sentence1'], batch['sentence2'], max_length=max_len, truncation=True)\n",
    "\n",
    "dataset_train_tokenized = dataset_train.map(tokenize, batched=True, batch_size=len(dataset_train))\n",
    "dataset_val_tokenized = dataset_val.map(tokenize, batched=True, batch_size=len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_tokenized, dataset_val_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokenized datasets to PyTorch tensors\n",
    "dataset_train_tokenized = dataset_train_tokenized.rename_column(\"label\", \"labels\")\n",
    "dataset_train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "dataset_val_tokenized = dataset_val_tokenized.rename_column(\"label\", \"labels\")\n",
    "dataset_val_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload tokenized dataset to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we processed the datasets we are going to use the new `FileSystem` [integration](https://huggingface.co/docs/datasets/filesystems.html) to upload our dataset to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "s3_prefix = 'sts-paws-datasets/paws-tokenized/' + tokenizer_and_model_name\n",
    "\n",
    "# save train dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "dataset_train_tokenized.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save val dataset to s3\n",
    "val_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/val'\n",
    "dataset_val_tokenized.save_to_disk(val_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training: Amazon SageMaker - Hugging Face\n",
    "\n",
    "BERT stands for Bidirectional Encoder Representations from Transformers, a transformer based model that uses Attention mechanism for learning contextual relationships among words of a sentence. With Hugging Face library, we can take a pre-trained BERT model that has learned contextual relationships from Wikipedia, books, other corpus, and fine tune the model on a specific set of paraphrase sentence pairs.\n",
    "\n",
    "![](img/bert_transfer_learning.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustration is from Jacob D. et al (2019). The overall pre-training and fine-tuning procedure for BERT. Retrieved from https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other resources for learning more about transfer learning and BERT include - 1) [Recent Advances in Language Model Fine-tuning](https://ruder.io/recent-advances-lm-fine-tuning/) by Sebastian Ruder; 2) [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar; 3) [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805); 4) [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) and 5) [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are done with data preparation, we are ready to fine-tune our pre-trained roberta-large model on the task of identifying paraphrased sentences. We can leverage the HuggingFace Estimator class within SageMaker to initiate the fine-tuning process in a few simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: when fine-tuning HuggingFace transformers, ensure that the `transformers_version`, `pytorch_version` and `py_version` are aligned, as described [here](https://huggingface.co/docs/sagemaker/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 4,\n",
    "                   'train_batch_size': 16,\n",
    "                   'model_name': tokenizer_and_model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional: View session bucket name\n",
    "# f's3://{sess.default_bucket()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "                            entry_point='train.py',\n",
    "                            source_dir='./scripts',\n",
    "                            output_path=f's3://{sess.default_bucket()}',\n",
    "                            base_job_name='huggingface-sdk-extension',\n",
    "                            instance_type='ml.p3.8xlarge',\n",
    "                            instance_count=1,\n",
    "                            volume_size=100,\n",
    "                            transformers_version='4.6.1',\n",
    "                            pytorch_version='1.7.1',\n",
    "                            py_version='py36',\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            metric_definitions=metric_definitions\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be calling our `train.py` file store in `./scripts/train.py`, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Optional: View training script\n",
    "# !pygmentize ./scripts/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Begin fine-tuning\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': val_input_path}, \n",
    "                          wait=True, \n",
    "                          job_name='sm-sts-blog-{}'.format(int(time.time())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/sagemaker-training-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the trained model to an endpoint, we call the `deploy()` method on the HuggingFace estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_estimator.deploy(initial_instance_count=1,\n",
    "                                         instance_type=\"ml.g4dn.xlarge\", \n",
    "                                         endpoint_name=\"sts-sbert-paws\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Alternativel, we can also load the fine-tuned model from s3, if one has been trained previously.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: comment out cells below after final review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# sm_client = boto3.client('sagemaker')\n",
    "# bucket_name = 'sts-sbert-paws-blog'\n",
    "# latest_sm_training_job_name = sm_client.list_training_jobs()['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "\n",
    "# S3_PATH_TRAINED_MODEL_FILE = 's3://' + bucket_name + '/' + latest_sm_training_job_name + '/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recreate the huggingface_model object\n",
    "\n",
    "# from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# huggingface_model = HuggingFaceModel(\n",
    "#     model_data=S3_PATH_TRAINED_MODEL_FILE,\n",
    "#     role=role,\n",
    "#     transformers_version='4.6.1',\n",
    "#     pytorch_version='1.7.1',\n",
    "#     py_version='py36',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = huggingface_model.deploy(initial_instance_count=1,\n",
    "#                                      instance_type='ml.g4dn.xlarge', \n",
    "#                                      endpoint_name='sts-sbert-paws')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other scenarios to deploy a model to a SageMaker endpoint include - 1) from a model stored in the [Hugging Face Hub](https://huggingface.co/models) and 2) by using a custom inference container. For more information on these methods refer to [Announcing managed inference for Hugging Face models in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is deployed, we can send observations from the unseen test dataset - `df_test` to the endpoint, to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a few sentences from the test dataset and send it to the endpoint for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run this cell to see predictions on alternative sample test inputs\n",
    "\n",
    "import random \n",
    "\n",
    "rand = random.randrange(0, 8000)\n",
    "\n",
    "true_label = dataset_test[rand]['label']\n",
    "sent_1 = dataset_test[rand]['sentence1']\n",
    "sent_2 = dataset_test[rand]['sentence2']\n",
    "\n",
    "sentence_pair = {\"inputs\": ['[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]']}\n",
    "\n",
    "print('Sentence 1:', sent_1) \n",
    "print('Sentence 2:', sent_2)\n",
    "print()\n",
    "print('True Label:', true_label)\n",
    "print('Predicted Label:', predictor.predict(sentence_pair)[0]['label'])\n",
    "print('Prediction Confidence:', predictor.predict(sentence_pair)[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the fine-tuned model on the whole unseen test set and evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of test set records:', len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "# Inference takes ~5 minutes for all test records using a fine-tuned roberta-large and ml.g4dn.xlarge instance\n",
    "\n",
    "for i in tqdm(range(len(dataset_test))):\n",
    "    true_label = dataset_test[i]['label']\n",
    "    sent_1 = dataset_test[i]['sentence1']\n",
    "    sent_2 = dataset_test[i]['sentence2']\n",
    "    \n",
    "    sentence_pair = {\"inputs\": ['[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]']}\n",
    "    pred = predictor.predict(sentence_pair)\n",
    "    \n",
    "    labels.append(true_label)\n",
    "    preds.append(int(pred[0]['label'].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Endpoint Name:', predictor.endpoint_name)\n",
    "class_names = ['paraphase', 'not paraphrase']\n",
    "print(classification_report(labels, preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the test set scores above, we can see roberta-large has a combined f1-score of 93% and performs equally well across both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are done with the endpoint, we can delete it to save cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Use Hugging Face with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html)\n",
    "2. [Hugging Face sample notebooks](https://github.com/huggingface/notebooks/tree/master/sagemaker)\n",
    "3. [AWS Blog - AWS and Hugging Face collaborate to simplify and accelerate adoption of Natural Language Processing models](https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-simplify-and-accelerate-adoption-of-natural-language-processing-models/)\n",
    "4. [AWS Blog - Announcing managed inference for Hugging Face models in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/)\n",
    "5. [The Partnership: Amazon SageMaker and Hugging Face](https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face)\n",
    "6. Sarker A, Gonzalez G. Portable automatic text classification for adverse drug reaction detection via multi-corpus training. J Biomed Inform. 2015;53:196-207. doi:10.1016/j.jbi.2014.11.002\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

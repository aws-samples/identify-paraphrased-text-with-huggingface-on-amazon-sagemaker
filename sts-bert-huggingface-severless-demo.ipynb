{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ce682b",
   "metadata": {},
   "source": [
    "# Paraphrase Identification using HuggingFace on SageMaker - Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53739b08",
   "metadata": {},
   "source": [
    "Many customers today deal with use cases where identifying paraphrased text has business value. For example, by identifying sentence paraphrases, a text summarization system could remove redundant information. Another application is to identify plagiarized documents. Here, we will fine-tune a Hugging Face transformer on SageMaker to identify paraphrased sentence pairs in a few, simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe463520",
   "metadata": {},
   "source": [
    "# Setup and install libraries\n",
    "\n",
    "We will begin by installing the necessary libraries, importing them into the development environment, selecting the appropriate IAM role and the Amazon S3 bucket.\n",
    "\n",
    "Select the `conda_pytorch_p36` notebook kernel\n",
    "\n",
    "Install the required libraries from Hugging Face - `transformers` and `datasets`. We'll also ensure that we have the updated version of `SageMaker Python SDK`\n",
    "\n",
    "Documentation on [Installing Transformers](https://huggingface.co/docs/transformers/installation) and [Installing SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk/tree/master)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89018c",
   "metadata": {},
   "source": [
    "Note: if you see the following message after executing the pip install cell below, you can safely ignore it, it does not affect the packages and code in this notebook: \"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\n",
    "spacy 3.0.6 requires pydantic<1.8.0,>=1.7.1, but you have pydantic 1.8.2 which is incompatible.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install \"sagemaker\" \"transformers==4.6.1\" \"datasets==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface\n",
    "import sagemaker\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "print(f\"SageMaker Role Arn: {role}\")\n",
    "print(f\"SageMaker - Amazon S3 Bucket: {bucket}\")\n",
    "print(f\"SageMaker Session Region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab65e5",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586b104",
   "metadata": {},
   "source": [
    "We will be using the `PAWS (Paraphrase Adversaries from Word Scrambling)` dataset. The final labled dataset contains pairs that are genreated from both word swapping and back translation methods. All pairs have human judgements on both paraphrasing and fluency and they are also split into `Train/Validation/Test` sections. The `Train` dataset contains a total of 49,401 sentence pairs, while the `Validation` and `Test` datasets contain a total of 8,000 sentence pairs each.\n",
    "\n",
    "![image info](./img/PAWS-dataset-sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, dataset_test = load_dataset(\"paws\", \"labeled_final\", split=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b4554",
   "metadata": {},
   "source": [
    "# Understand Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a490bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = dataset_train.to_pandas()\n",
    "\n",
    "ax = sns.countplot(x=\"label\", data=df)\n",
    "ax.set_title('Label Count for PAWS Dataset', fontsize=15)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), ha='center', va='top', color='white', size=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ec2d0",
   "metadata": {},
   "source": [
    "We can see the dataset is slightly imbalanced, a few class imbalance strategies can be applied such as _oversampling_, _undersampling_, _SMOTE_, etc. For the purpose of demonstration, we will not implement these strategies and assume that we have a fairly balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef50e4",
   "metadata": {},
   "source": [
    "# Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac96269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer_and_model_name = 'roberta-large'\n",
    "\n",
    "# Download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_and_model_name)\n",
    "\n",
    "# Tokenizer helper function\n",
    "def tokenize(batch, max_len=128):\n",
    "    return tokenizer(batch['sentence1'], batch['sentence2'], max_length=max_len, truncation=True)\n",
    "\n",
    "dataset_train_tokenized = dataset_train.map(tokenize, batched=True, batch_size=len(dataset_train))\n",
    "dataset_val_tokenized = dataset_val.map(tokenize, batched=True, batch_size=len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2657718",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_tokenized, dataset_val_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokenized datasets to PyTorch tensors\n",
    "dataset_train_tokenized = dataset_train_tokenized.rename_column(\"label\", \"labels\")\n",
    "dataset_train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "dataset_val_tokenized = dataset_val_tokenized.rename_column(\"label\", \"labels\")\n",
    "dataset_val_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e29a2",
   "metadata": {},
   "source": [
    "# Upload tokenized dataset to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891cceb",
   "metadata": {},
   "source": [
    "After we processed the datasets we are going to use the new `FileSystem` [integration](https://huggingface.co/docs/datasets/filesystems.html) to upload our dataset to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42242ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "s3_prefix = 'sts-paws-datasets/paws-tokenized/' + tokenizer_and_model_name\n",
    "\n",
    "# save train dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "dataset_train_tokenized.save_to_disk(training_input_path,fs=s3)\n",
    "\n",
    "# save val dataset to s3\n",
    "val_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/val'\n",
    "dataset_val_tokenized.save_to_disk(val_input_path,fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77737ba8",
   "metadata": {},
   "source": [
    "# Model Training: Amazon SageMaker - Hugging Face\n",
    "\n",
    "![](img/bert_transfer_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452adc6",
   "metadata": {},
   "source": [
    "This illustration is from Jacob D. et al (2019). The overall pre-training and fine-tuning procedure for BERT. Retrieved from https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66478323",
   "metadata": {},
   "source": [
    "Other resources for learning more about transfer learning and BERT include - 1) [Recent Advances in Language Model Fine-tuning](https://ruder.io/recent-advances-lm-fine-tuning/) by Sebastian Ruder; 2) [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar; 3) [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805); 4) [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) and 5) [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32219f",
   "metadata": {},
   "source": [
    "# Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad2b3c",
   "metadata": {},
   "source": [
    "Now that we are done with data preparation, we are ready to fine-tune our pre-trained roberta-base model on the task of identifying paraphrased sentences. We can leverage the HuggingFace Estimator class within SageMaker to initiate the fine-tuning process in a few simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c33424",
   "metadata": {},
   "source": [
    "\n",
    "Note: when fine-tuning HuggingFace transformers, ensure that the `transformers_version`, `pytorch_version` and `py_version` are aligned, as described [here](https://huggingface.co/docs/sagemaker/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional: View session bucket name\n",
    "# f's3://{sess.default_bucket()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1', 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace, TrainingCompilerConfig\n",
    "\n",
    "hyperparameters = {'epochs': 4,\n",
    "                   'train_batch_size': 16,\n",
    "                   'model_name': tokenizer_and_model_name}\n",
    "\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "                            entry_point='train.py',\n",
    "                            source_dir='./scripts',\n",
    "                            output_path=f's3://{sess.default_bucket()}',\n",
    "                            base_job_name='huggingface-sdk-extension',\n",
    "                            instance_type='ml.p3.8xlarge',\n",
    "                            instance_count=1,\n",
    "                            volume_size=100,\n",
    "                            transformers_version='4.6.1',\n",
    "                            pytorch_version='1.7.1',\n",
    "                            py_version='py36',\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            metric_definitions=metric_definitions\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ed9da",
   "metadata": {},
   "source": [
    "We will be calling our `train.py` file store in `./scripts/train.py`, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional: View training script\n",
    "# !pygmentize ./scripts/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Begin fine-tuning\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': val_input_path}, \n",
    "                          wait=True, \n",
    "                          job_name='sm-sts-blog-{}'.format(int(time.time())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce95823",
   "metadata": {},
   "source": [
    "![](./img/sagemaker-training-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae2d07",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781991fa",
   "metadata": {},
   "source": [
    "## SageMaker Endpoint Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648050c4",
   "metadata": {},
   "source": [
    "To deploy the trained model to an endpoint, we call the `deploy()` method on the HuggingFace estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_predictor = huggingface_estimator.deploy(initial_instance_count=1,\n",
    "                                         instance_type=\"ml.g4dn.xlarge\", \n",
    "                                         endpoint_name=\"sts-sbert-paws-roberta-base-realtime-inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4ccd6",
   "metadata": {},
   "source": [
    "**Optional: Alternatively, we can also load a previously fine-tuned model from s3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# sm_client = boto3.client('sagemaker')\n",
    "# bucket_name = 'sts-sbert-paws-blog'\n",
    "# latest_sm_training_job_name = sm_client.list_training_jobs()['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "\n",
    "# S3_PATH_TRAINED_MODEL_FILE = 's3://' + bucket_name + '/' + latest_sm_training_job_name + '/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Selected SageMaker Training Job Name:', latest_sm_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recreate the huggingface_model object\n",
    "\n",
    "# from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# huggingface_model = HuggingFaceModel(\n",
    "#     model_data=S3_PATH_TRAINED_MODEL_FILE,\n",
    "#     role=role,\n",
    "#     transformers_version='4.6.1',\n",
    "#     pytorch_version='1.7.1',\n",
    "#     py_version='py36',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac022e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt_predictor = huggingface_estimator.deploy(initial_instance_count=1,\n",
    "#                                      instance_type='ml.g4dn.xlarge', \n",
    "#                                      endpoint_name='sts-sbert-paws-roberta-base-realtime-inference',\n",
    "#                                      wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403dd299",
   "metadata": {},
   "source": [
    "Other scenarios to deploy a model to a SageMaker endpoint include - 1) from a model stored in the [Hugging Face Hub](https://huggingface.co/models) and 2) by using a custom inference container. For more information on these methods refer to [Announcing managed inference for Hugging Face models in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09044ae3",
   "metadata": {},
   "source": [
    "## SageMaker Serverless Endpoint Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687e9b6",
   "metadata": {},
   "source": [
    "First create a serverless config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc739e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe37388",
   "metadata": {},
   "source": [
    "Retrieve the image uri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc77a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"huggingface\",\n",
    "    base_framework_version=\"pytorch1.7\",\n",
    "    region=sess.boto_region_name,\n",
    "    version=\"4.6\",\n",
    "    py_version=\"py36\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2083762",
   "metadata": {},
   "source": [
    "Create serverless inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98892b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_predictor = huggingface_estimator.deploy(\n",
    "    endpoint_name= \"huggingface-serverless-ep\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime()),\n",
    "    serverless_inference_config=serverless_config,\n",
    "    image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c6fe6",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run this cell to see predictions on alternative sample test inputs\n",
    "\n",
    "import random \n",
    "\n",
    "rand = random.randrange(0, 8000)\n",
    "\n",
    "true_label = dataset_test[rand]['label']\n",
    "sent_1 = dataset_test[rand]['sentence1']\n",
    "sent_2 = dataset_test[rand]['sentence2']\n",
    "\n",
    "sentence_pair = '[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21184c5a",
   "metadata": {},
   "source": [
    "## Inference using SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ab6b8",
   "metadata": {},
   "source": [
    "Once the model is deployed, we can send observations from the unseen test dataset - `df_test` to the endpoint, to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b2064",
   "metadata": {},
   "source": [
    "Let's select a few sentences from the test dataset and send it to the real-time endpoint for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sentence 1:', sent_1) \n",
    "print('Sentence 2:', sent_2)\n",
    "print()\n",
    "print('Inference Endpoint:', rt_predictor.endpoint_name)\n",
    "print('True Label:', true_label)\n",
    "print('Predicted Label:', rt_predictor.predict({\"inputs\": sentence_pair})[0]['label'])\n",
    "print('Prediction Confidence:', rt_predictor.predict({\"inputs\": sentence_pair})[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2544b9f",
   "metadata": {},
   "source": [
    "## Inference using SageMaker Serverless Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba2548",
   "metadata": {},
   "source": [
    "Invoking serverless inference endpoint works the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09185687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sentence 1:', sent_1) \n",
    "print('Sentence 2:', sent_2)\n",
    "print()\n",
    "print('Inference Endpoint:', sl_predictor.endpoint_name)\n",
    "print('True Label:', true_label)\n",
    "print('Predicted Label:', sl_predictor.predict({\"inputs\": sentence_pair})[0]['label'])\n",
    "print('Prediction Confidence:', sl_predictor.predict({\"inputs\": sentence_pair})[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aae6a7",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e5098",
   "metadata": {},
   "source": [
    "Let's apply the fine-tuned model on the whole unseen test set and evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of test set records:', len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "# Inference takes ~5 minutes for 8,000 test records using a fine-tuned roberta-large and ml.g4dn.xlarge instance\n",
    "\n",
    "for i in tqdm(range(len(dataset_test))):\n",
    "    true_label = dataset_test[i]['label']\n",
    "    sent_1 = dataset_test[i]['sentence1']\n",
    "    sent_2 = dataset_test[i]['sentence2']\n",
    "    \n",
    "    sentence_pair = {\"inputs\": ['[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]']}\n",
    "    pred = rt_predictor.predict(sentence_pair)\n",
    "    \n",
    "    labels.append(true_label)\n",
    "    preds.append(int(pred[0]['label'].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246be254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Endpoint Name:', rt_predictor.endpoint_name)\n",
    "class_names = ['paraphase', 'not paraphrase']\n",
    "print(classification_report(labels, preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0621a",
   "metadata": {},
   "source": [
    "We will also test the performance on Serverless Inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds2 = []\n",
    "labels2 = []\n",
    "\n",
    "# Inference takes ~5 minutes for 8,000 test records using a fine-tuned roberta-large and ml.g4dn.xlarge instance\n",
    "\n",
    "for i in tqdm(range(len(dataset_test))):\n",
    "    true_label = dataset_test[i]['label']\n",
    "    sent_1 = dataset_test[i]['sentence1']\n",
    "    sent_2 = dataset_test[i]['sentence2']\n",
    "    \n",
    "    sentence_pair = {\"inputs\": ['[CLS] ' + sent_1 + ' [SEP] ' + sent_2 + ' [SEP]']}\n",
    "    pred = sl_predictor.predict(sentence_pair)\n",
    "    \n",
    "    labels2.append(true_label)\n",
    "    preds2.append(int(pred[0]['label'].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Endpoint Name:', rt_predictor.endpoint_name)\n",
    "class_names = ['paraphase', 'not paraphrase']\n",
    "print(classification_report(labels2, preds2, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5b44d",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a28cd6",
   "metadata": {},
   "source": [
    "When we are done with the endpoint, we can delete it to save cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete real-time endpoint\n",
    "rt_predictor.delete_model()\n",
    "rt_predictor.delete_endpoint()\n",
    "\n",
    "# delete severless endpoint\n",
    "sl_predictor.delete_model()\n",
    "sl_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd818f74",
   "metadata": {},
   "source": [
    "# Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f7c24",
   "metadata": {},
   "source": [
    "1. [Use Hugging Face with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html)\n",
    "2. [Hugging Face sample notebooks](https://github.com/huggingface/notebooks/tree/master/sagemaker)\n",
    "3. [AWS Blog - AWS and Hugging Face collaborate to simplify and accelerate adoption of Natural Language Processing models](https://aws.amazon.com/blogs/machine-learning/aws-and-hugging-face-collaborate-to-simplify-and-accelerate-adoption-of-natural-language-processing-models/)\n",
    "4. [AWS Blog - Announcing managed inference for Hugging Face models in Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/announcing-managed-inference-for-hugging-face-models-in-amazon-sagemaker/)\n",
    "5. [The Partnership: Amazon SageMaker and Hugging Face](https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face)\n",
    "6. Sarker A, Gonzalez G. Portable automatic text classification for adverse drug reaction detection via multi-corpus training. J Biomed Inform. 2015;53:196-207. doi:10.1016/j.jbi.2014.11.002\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
